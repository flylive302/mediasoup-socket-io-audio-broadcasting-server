# ELITE REMEDIATION PLAN — Seat Domain

## 1. Executive Summary

Remediation of **14 findings** from the seat domain forensic audit (`docs/audits/2026-02-12-0407-seat-domain.md`). Organized into **4 atomic PRs** across **2 sprints**, totaling **~11.6 hours**.

Key themes: TOCTOU race elimination via Lua atomicity, memory leak fix, O(1) reverse index for user→seat lookups, and dead code removal.

## 2. Audit Reference

| Key    | Value                                        |
| ------ | -------------------------------------------- |
| Audit  | `docs/audits/2026-02-12-0407-seat-domain.md` |
| Commit | `a4db816`                                    |
| Branch | `work`                                       |
| Domain | `src/domains/seat/` (15 files)               |

---

## 3. Per-Issue Remediation Details

---

### SEAT-001 — Lock TOCTOU Race

```
Issue ID: SEAT-001
Severity: CRITICAL
Files Touched:
  - src/domains/seat/seat.repository.ts
  - src/domains/seat/handlers/lock-seat.handler.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.repository.ts (LOCK_SEAT_SCRIPT Lua)
+++ b/src/domains/seat/seat.repository.ts
   local seatsKey = KEYS[1]
   local lockedKey = KEYS[2]
   local seatIndex = ARGV[1]
+  -- Atomic: check if already locked INSIDE the script
+  if redis.call('SISMEMBER', lockedKey, seatIndex) == 1 then
+    return cjson.encode({success = false, error = "ALREADY_LOCKED"})
+  end
   local kicked = false
   local existing = redis.call('HGET', seatsKey, seatIndex)
```

```diff
--- a/src/domains/seat/seat.repository.ts (lockSeat method)
+++ b/src/domains/seat/seat.repository.ts
-  async lockSeat(roomId: string, seatIndex: number): Promise<{ kicked: string | null }> {
+  async lockSeat(roomId: string, seatIndex: number): Promise<SeatActionResult & { kicked?: string | null }> {
     const result = ... // parse includes success/error/kicked
+    if (!parsed.success) {
+      parsed.error = this.mapError(parsed.error);
+    }
```

```diff
--- a/src/domains/seat/handlers/lock-seat.handler.ts
+++ b/src/domains/seat/handlers/lock-seat.handler.ts
-    // Check if already locked (using Redis)
-    const alreadyLocked = await context.seatRepository.isSeatLocked(roomId, seatIndex);
-    if (alreadyLocked) {
-      return { success: false, error: Errors.SEAT_ALREADY_LOCKED };
-    }
-
     // Lock the seat (kicks occupant if any) — now atomic
-    const { kicked } = await context.seatRepository.lockSeat(roomId, seatIndex);
+    const lockResult = await context.seatRepository.lockSeat(roomId, seatIndex);
+    if (!lockResult.success) {
+      return { success: false, error: lockResult.error };
+    }
+    const kicked = lockResult.kicked;
```

Downstream Callsites:

- `src/domains/seat/handlers/lock-seat.handler.ts:33` — lockSeatHandler
- `src/domains/seat/seat.repository.ts:307` — lockSeat()

Runtime Risk: None — Lua SISMEMBER check is O(1), same as the removed handler-level call
Rollback: `git revert <commit>` — old behavior is functionally identical, just non-atomic
Hours: 1
Owner: AI/Developer
Priority: P1

Tests Required:

- `seat.repository.test.ts` — "lockSeat returns ALREADY_LOCKED when seat is already locked"
- `seat.repository.test.ts` — "lockSeat atomically checks and locks in single EVALSHA"

---

### SEAT-002 — Unlock TOCTOU Race

```
Issue ID: SEAT-002
Severity: CRITICAL
Files Touched:
  - src/domains/seat/seat.repository.ts
  - src/domains/seat/handlers/unlock-seat.handler.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.repository.ts
+++ b/src/domains/seat/seat.repository.ts
+const UNLOCK_SEAT_SCRIPT = `
+  local lockedKey = KEYS[1]
+  local seatIndex = ARGV[1]
+  if redis.call('SISMEMBER', lockedKey, seatIndex) == 0 then
+    return cjson.encode({success = false, error = "NOT_LOCKED"})
+  end
+  redis.call('SREM', lockedKey, seatIndex)
+  return cjson.encode({success = true})
+`;
```

```diff
--- a/src/domains/seat/seat.repository.ts (unlockSeat method)
+++ b/src/domains/seat/seat.repository.ts
-  async unlockSeat(roomId: string, seatIndex: number): Promise<boolean> {
-    await this.redis.srem(LOCKED_KEY(roomId), seatIndex.toString());
-    return true;
+  async unlockSeat(roomId: string, seatIndex: number): Promise<SeatActionResult> {
+    const result = await (this.redis as never as RedisWithCommands).seatUnlock(
+      LOCKED_KEY(roomId), seatIndex.toString(),
+    );
+    const parsed = JSON.parse(result) as SeatActionResult;
+    if (!parsed.success) parsed.error = this.mapError(parsed.error);
+    return parsed;
```

```diff
--- a/src/domains/seat/handlers/unlock-seat.handler.ts
+++ b/src/domains/seat/handlers/unlock-seat.handler.ts
-    const isLocked = await context.seatRepository.isSeatLocked(roomId, seatIndex);
-    if (!isLocked) {
-      return { success: false, error: Errors.SEAT_NOT_LOCKED };
-    }
-    await context.seatRepository.unlockSeat(roomId, seatIndex);
+    const result = await context.seatRepository.unlockSeat(roomId, seatIndex);
+    if (!result.success) {
+      return { success: false, error: result.error };
+    }
```

Downstream Callsites:

- `src/domains/seat/handlers/unlock-seat.handler.ts:33` — unlockSeatHandler
- `src/domains/seat/handlers/invite-response.handler.ts:63` — inviteAcceptHandler (auto-unlock)

Runtime Risk: `invite-response.handler.ts` also calls `unlockSeat()` — must handle new return type (currently ignores result)
Rollback: `git revert <commit>`
Hours: 1
Owner: AI/Developer
Priority: P1

Tests Required:

- `seat.repository.test.ts` — "unlockSeat returns NOT_LOCKED when seat is not locked"
- `seat.repository.test.ts` — "unlockSeat atomically checks and removes in single EVALSHA"

---

### SEAT-003 — Invite-Accept Race Window (4 Sequential Redis Ops)

```
Issue ID: SEAT-003
Severity: HIGH
Files Touched:
  - src/domains/seat/seat.repository.ts
  - src/domains/seat/handlers/invite-response.handler.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.repository.ts
+++ b/src/domains/seat/seat.repository.ts
+const INVITE_ACCEPT_SCRIPT = `
+  local seatsKey   = KEYS[1]
+  local lockedKey  = KEYS[2]
+  local inviteKey  = KEYS[3]
+  local reverseKey = KEYS[4]
+  local seatIndex  = tonumber(ARGV[1])
+  local userId     = ARGV[2]
+  local seatCount  = tonumber(ARGV[3])
+
+  -- 1. Read & validate invite
+  local inviteData = redis.call('GET', inviteKey)
+  if not inviteData then
+    return cjson.encode({success = false, error = "NO_INVITE"})
+  end
+  local invite = cjson.decode(inviteData)
+  if invite.targetUserId ~= userId then
+    return cjson.encode({success = false, error = "NO_INVITE"})
+  end
+
+  -- 2. Delete invite + reverse index
+  redis.call('DEL', inviteKey)
+  redis.call('DEL', reverseKey)
+
+  -- 3. Auto-unlock if locked
+  local wasLocked = redis.call('SREM', lockedKey, tostring(seatIndex))
+
+  -- 4. Validate seat index
+  if seatIndex < 0 or seatIndex >= seatCount then
+    return cjson.encode({success = false, error = "SEAT_INVALID"})
+  end
+
+  -- 5. Remove user from any existing seat
+  local allSeats = redis.call('HGETALL', seatsKey)
+  for i = 1, #allSeats, 2 do
+    local data = cjson.decode(allSeats[i + 1])
+    if data.userId == userId then
+      redis.call('HDEL', seatsKey, allSeats[i])
+    end
+  end
+
+  -- 6. Take the seat
+  local seatData = cjson.encode({userId = userId, muted = false})
+  redis.call('HSET', seatsKey, tostring(seatIndex), seatData)
+
+  return cjson.encode({success = true, seatIndex = seatIndex, wasLocked = wasLocked > 0})
+`;
```

```diff
--- a/src/domains/seat/handlers/invite-response.handler.ts
+++ b/src/domains/seat/handlers/invite-response.handler.ts
-    await context.seatRepository.deleteInvite(roomId, seatIndex);
-    socket.nsp.to(roomId).emit("seat:invite:pending", { ... });
-    const isLocked = await context.seatRepository.isSeatLocked(...);
-    if (isLocked) { await context.seatRepository.unlockSeat(...); ... }
-    const result = await context.seatRepository.takeSeat(...);
+    const result = await context.seatRepository.atomicInviteAccept(
+      roomId, userId, seatIndex, config.DEFAULT_SEAT_COUNT,
+    );
+    if (!result.success) return { success: false, error: result.error };
+    socket.nsp.to(roomId).emit("seat:invite:pending", { seatIndex, isPending: false });
+    if (result.wasLocked) {
+      socket.nsp.to(roomId).emit("seat:locked", { seatIndex, isLocked: false });
+    }
```

Downstream Callsites:

- `src/domains/seat/handlers/invite-response.handler.ts:52-74` — inviteAcceptHandler

Runtime Risk: New Lua script must be thoroughly tested — handles 6 operations atomically
Rollback: `git revert <commit>` — old 4-step flow still works, just has race window
Hours: 2
Owner: AI/Developer
Priority: P1

Tests Required:

- `seat.repository.test.ts` — "atomicInviteAccept succeeds with valid invite"
- `seat.repository.test.ts` — "atomicInviteAccept returns NO_INVITE when expired"
- `seat.repository.test.ts` — "atomicInviteAccept auto-unlocks locked seat"
- `seat.repository.test.ts` — "atomicInviteAccept removes user from old seat"

---

### SEAT-004 — Unbounded roomOwnerCache Memory Leak

```
Issue ID: SEAT-004
Severity: HIGH
Files Touched:
  - src/domains/seat/seat.owner.ts
  - src/domains/room/roomManager.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.owner.ts
+++ b/src/domains/seat/seat.owner.ts
+// Periodic cache cleanup — evict expired entries every 60s
+const CACHE_PRUNE_INTERVAL_MS = 60_000;
+const pruneInterval = setInterval(() => {
+  const now = Date.now();
+  for (const [roomId, entry] of roomOwnerCache) {
+    if (entry.expiresAt <= now) roomOwnerCache.delete(roomId);
+  }
+}, CACHE_PRUNE_INTERVAL_MS);
+pruneInterval.unref(); // Don't block process exit
```

```diff
--- a/src/domains/room/roomManager.ts (closeRoom method)
+++ b/src/domains/room/roomManager.ts
+import { clearRoomOwner } from "@src/domains/seat/index.js";
 // In closeRoom cleanup:
+    clearRoomOwner(roomId);
```

Downstream Callsites:

- `src/domains/seat/seat.owner.ts:38` — clearRoomOwner (currently dead code, now called)
- `src/domains/room/roomManager.ts:180-186` — closeRoom cleanup path

Runtime Risk: `.unref()` on interval prevents blocking process exit. clearRoomOwner is safe — just a Map.delete()
Rollback: `git revert <commit>`
Hours: 1
Owner: AI/Developer
Priority: P0

Tests Required:

- Unit test — "clearRoomOwner removes entry from cache"
- Unit test — "pruneInterval evicts expired entries"

---

### SEAT-005 — getUserSeat O(n) Scan → O(1) Reverse Index

```
Issue ID: SEAT-005
Severity: HIGH
Files Touched:
  - src/domains/seat/seat.repository.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.repository.ts
+++ b/src/domains/seat/seat.repository.ts
+const USER_SEAT_KEY = (roomId: string, userId: string) =>
+  `room:${roomId}:seat:user:${userId}`;

 // In TAKE_SEAT_SCRIPT Lua — after HSET:
+  redis.call('SET', KEYS[3], tostring(seatIndex))  -- KEYS[3] = user seat reverse index
   -- In the "remove from old seat" loop, also DEL old reverse index

 // In LEAVE_SEAT_SCRIPT Lua — after HDEL:
+  redis.call('DEL', KEYS[2])  -- KEYS[2] = user seat reverse index
```

```diff
--- a/src/domains/seat/seat.repository.ts (getUserSeat method)
+++ b/src/domains/seat/seat.repository.ts
   async getUserSeat(roomId: string, userId: string): Promise<number | null> {
-    const seatsData = await this.redis.hgetall(SEATS_KEY(roomId));
-    for (const [index, seatStr] of Object.entries(seatsData)) {
-      const data = JSON.parse(seatStr) as SeatAssignment;
-      if (data.userId === userId) return parseInt(index, 10);
-    }
-    return null;
+    const seatIndexStr = await this.redis.get(USER_SEAT_KEY(roomId, userId));
+    return seatIndexStr ? parseInt(seatIndexStr, 10) : null;
   }
```

Downstream Callsites:

- `src/domains/seat/handlers/mute-seat.handler.ts:26` — muteSeatHandler
- `src/domains/seat/handlers/unmute-seat.handler.ts:26` — unmuteSeatHandler

Runtime Risk: Must update ALL Lua scripts (take, leave, assign) to maintain the reverse index. Missing a write = stale index
Rollback: `git revert <commit>` — old HGETALL scan still works
Hours: 2
Owner: AI/Developer
Priority: P2

Tests Required:

- `seat.repository.test.ts` — "getUserSeat returns seat via O(1) reverse index"
- `seat.repository.test.ts` — "takeSeat writes user→seat reverse index"
- `seat.repository.test.ts` — "leaveSeat deletes user→seat reverse index"

---

### SEAT-006 — clearRoomOwner Dead Code

```
Issue ID: SEAT-006
Severity: MEDIUM
Files Touched:
  - src/domains/room/roomManager.ts
```

Patch Sketch: **Resolved by SEAT-004** — clearRoomOwner is now called in closeRoom()

Downstream Callsites: N/A (was dead, now wired)
Runtime Risk: None
Rollback: N/A
Hours: 0 (included in SEAT-004)
Owner: AI/Developer
Priority: P3

---

### SEAT-007 — Unused SEAT_UNAVAILABLE Error

```
Issue ID: SEAT-007
Severity: MEDIUM
Files Touched:
  - src/shared/errors.ts
```

Patch Sketch:

```diff
--- a/src/shared/errors.ts
+++ b/src/shared/errors.ts
   USER_NOT_SEATED: "User is not seated",
-  SEAT_UNAVAILABLE: "Seat is no longer available",
   MUTE_FAILED: "Failed to mute user",
```

Downstream Callsites: None (unused)
Runtime Risk: None — no references anywhere
Rollback: Re-add the line
Hours: 0.25
Owner: AI/Developer
Priority: P3

Tests Required: None

---

### SEAT-008 — Hardcoded .max(14) in Zod Schemas

```
Issue ID: SEAT-008
Severity: MEDIUM
Files Touched:
  - src/socket/schemas.ts
  - src/config/index.ts
```

Patch Sketch:

```diff
--- a/src/socket/schemas.ts
+++ b/src/socket/schemas.ts
+import { config } from "@src/config/index.js";
+const MAX_SEAT_INDEX = config.DEFAULT_SEAT_COUNT - 1;

-  seatIndex: z.number().int().min(0).max(14),
+  seatIndex: z.number().int().min(0).max(MAX_SEAT_INDEX),
```

Downstream Callsites:

- All seat schemas: seatTakeSchema, seatAssignSchema, seatLockSchema, seatInviteSchema, seatInviteActionSchema

Runtime Risk: If DEFAULT_SEAT_COUNT changes, all schemas auto-adjust. Could accept wider range if config is raised
Rollback: Revert to hardcoded .max(14)
Hours: 0.5
Owner: AI/Developer
Priority: P3

Tests Required:

- `schemas.test.ts` — "seatTakeSchema rejects seatIndex >= DEFAULT_SEAT_COUNT"

---

### SEAT-009 — config.DEFAULT_SEAT_COUNT vs Actual Room seatCount

```
Issue ID: SEAT-009
Severity: MEDIUM
Files Touched:
  - src/domains/seat/handlers/take-seat.handler.ts
  - src/domains/seat/handlers/assign-seat.handler.ts
  - src/domains/seat/handlers/invite-response.handler.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/handlers/take-seat.handler.ts
+++ b/src/domains/seat/handlers/take-seat.handler.ts
+    // Read actual room seatCount from state
+    const roomState = await context.roomManager.state.get(roomId);
+    const seatCount = roomState?.seatCount ?? config.DEFAULT_SEAT_COUNT;

     const result = await context.seatRepository.takeSeat(
       roomId, userId, seatIndex,
-      config.DEFAULT_SEAT_COUNT,
+      seatCount,
     );
```

Downstream Callsites:

- `take-seat.handler.ts:21` — takeSeatHandler
- `assign-seat.handler.ts:29` — assignSeatHandler
- `invite-response.handler.ts:73` — inviteAcceptHandler

Runtime Risk: **Business logic change** — rooms with seatCount < 15 will now reject seat:take at higher indices. Need to confirm this is desired
Rollback: Revert to config.DEFAULT_SEAT_COUNT
Hours: 1
Owner: AI/Developer
Priority: P0

Tests Required:

- Handler test — "seat:take rejects seatIndex >= room seatCount"
- Handler test — "seat:take uses DEFAULT_SEAT_COUNT when state unavailable"

---

### SEAT-010 — Mute/Unmute Code Duplication

```
Issue ID: SEAT-010
Severity: MEDIUM
Files Touched:
  - src/domains/seat/handlers/mute-seat.handler.ts
  - src/domains/seat/handlers/unmute-seat.handler.ts
```

Patch Sketch:

```diff
+// New shared factory in handlers/mute-factory.ts
+export function createMuteHandler(muted: boolean) {
+  const eventLabel = muted ? "muted" : "unmuted";
+  const errorCode = muted ? Errors.MUTE_FAILED : Errors.UNMUTE_FAILED;
+  return createHandler("seat:" + (muted ? "mute" : "unmute"), seatMuteSchema,
+    async (payload, socket, context) => {
+      // auth → getUserSeat → setMute → producer.pause/resume → emit
+    });
+}

--- a/src/domains/seat/handlers/mute-seat.handler.ts
+++ b/src/domains/seat/handlers/mute-seat.handler.ts
-// 78-line handler
+export const muteSeatHandler = createMuteHandler(true);

--- a/src/domains/seat/handlers/unmute-seat.handler.ts
+++ b/src/domains/seat/handlers/unmute-seat.handler.ts
-// 78-line handler
+export const unmuteSeatHandler = createMuteHandler(false);
```

Downstream Callsites:

- `seat.handler.ts:14-15` — registers muteSeatHandler, unmuteSeatHandler

Runtime Risk: None — identical behavior
Rollback: Revert to separate files
Hours: 1
Owner: AI/Developer
Priority: P2

Tests Required:

- Existing tests still pass (mute/unmute behavior unchanged)

---

### SEAT-011 — Invite Doesn't Check If Target User Already Seated

```
Issue ID: SEAT-011
Severity: MEDIUM
Files Touched:
  - src/domains/seat/handlers/invite-seat.handler.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/handlers/invite-seat.handler.ts
+++ b/src/domains/seat/handlers/invite-seat.handler.ts
     const targetUserIdStr = String(targetUserId);

+    // Check if target user is already seated — accepting would silently move them
+    const existingSeat = await context.seatRepository.getUserSeat(roomId, targetUserIdStr);
+    if (existingSeat !== null) {
+      return { success: false, error: Errors.USER_ALREADY_SEATED };
+    }
+
     // Create invite with TTL in Redis
```

Downstream Callsites:

- `invite-seat.handler.ts:50` — inviteSeatHandler

Runtime Risk: New error code needed in `errors.ts`. Slight behavior change — currently allows inviting seated users
Rollback: Remove the check
Hours: 0.5
Owner: AI/Developer
Priority: P3

Tests Required:

- Handler test — "seat:invite rejects when target user is already seated"

---

### SEAT-012 — Inconsistent Auth Policy (Owner vs Manager)

```
Issue ID: SEAT-012
Severity: LOW
Files Touched:
  - src/domains/seat/seat.owner.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.owner.ts
+++ b/src/domains/seat/seat.owner.ts
 /**
  * Verify that a user is the room owner
+ *
+ * AUTH POLICY: Used for assign/remove — owner-only actions.
+ * For mute/lock/unlock/invite, use verifyRoomManager() which also allows admins.
  */
```

Downstream Callsites: N/A (documentation only)
Runtime Risk: None
Rollback: N/A
Hours: 0.25
Owner: AI/Developer
Priority: P4

Tests Required: None

---

### SEAT-013 — Handler Registration Log at INFO Level

```
Issue ID: SEAT-013
Severity: LOW
Files Touched:
  - src/domains/seat/seat.handler.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.handler.ts
+++ b/src/domains/seat/seat.handler.ts
-  logger.info({ socketId: socket.id, userId }, "Seat handlers registered");
+  logger.debug({ socketId: socket.id, userId }, "Seat handlers registered");
```

Downstream Callsites: N/A
Runtime Risk: None — reduces log noise
Rollback: Change back to info
Hours: 0.1
Owner: AI/Developer
Priority: P4

Tests Required: None

---

### SEAT-014 — deleteInvite Extra GET Round-Trip

```
Issue ID: SEAT-014
Severity: LOW
Files Touched:
  - src/domains/seat/seat.repository.ts
```

Patch Sketch:

```diff
--- a/src/domains/seat/seat.repository.ts
+++ b/src/domains/seat/seat.repository.ts
+const DELETE_INVITE_SCRIPT = `
+  local inviteKey  = KEYS[1]
+  local data = redis.call('GET', inviteKey)
+  redis.call('DEL', inviteKey)
+  if data then
+    local invite = cjson.decode(data)
+    local reverseKey = KEYS[2]
+    redis.call('DEL', reverseKey)
+  end
+  return 1
+`;
```

Downstream Callsites:

- `invite-response.handler.ts:52` — inviteAcceptHandler
- `invite-response.handler.ts:134` — inviteDeclineHandler

Runtime Risk: None — same logic, just atomic
Rollback: Revert to GET + pipeline
Hours: 0.5
Owner: AI/Developer
Priority: P4

Tests Required:

- `seat.repository.test.ts` — "deleteInvite atomically removes both keys in single EVALSHA"

---

### BONUS — getLockedSeats Redundancy in room.handler.ts

```
Issue ID: SEAT-BONUS
Severity: LOW
Files Touched:
  - src/domains/room/room.handler.ts
```

Patch Sketch:

```diff
--- a/src/domains/room/room.handler.ts
+++ b/src/domains/room/room.handler.ts
-      const [roomSeatsData, lockedSeats] = await Promise.all([
-        seatRepository.getSeats(roomId, seatCount),
-        seatRepository.getLockedSeats(roomId),
-      ]);
+      const roomSeatsData = await seatRepository.getSeats(roomId, seatCount);
+      // lockedSeats extracted from SeatData.locked — no separate Redis call needed
+      const lockedSeats = roomSeatsData
+        .filter(s => s.locked)
+        .map(s => s.index);
```

Downstream Callsites:

- `room.handler.ts:115-117` — room:join handler

Runtime Risk: None — same data, 1 fewer Redis call
Rollback: Re-add the parallel call
Hours: 0.25
Owner: AI/Developer
Priority: P3

Tests Required: None (existing join flow tests cover)

---

## 4. PR Patch Plan

| PR # | Title                                                           | Files | Depends On | Issues                                                     |
| ---- | --------------------------------------------------------------- | ----- | ---------- | ---------------------------------------------------------- |
| 1    | fix(seat): atomic lock/unlock + memory leak                     | 5     | —          | SEAT-001, SEAT-002, SEAT-004, SEAT-006                     |
| 2    | perf(seat): invite-accept atomicity + reverse index + seatCount | 6     | PR #1      | SEAT-003, SEAT-005, SEAT-009, SEAT-BONUS                   |
| 3    | refactor(seat): dead code + schema + duplication cleanup        | 7     | PR #2      | SEAT-007, SEAT-008, SEAT-010, SEAT-011, SEAT-013, SEAT-014 |
| 4    | docs(seat): auth policy documentation                           | 1     | —          | SEAT-012                                                   |

Each PR must pass:

- `npm run lint`
- `npm run typecheck`
- `npm run test`
- `npm run build`

---

## 5. Sprint Plan

| Sprint | Focus Area                   | PRs  | Hours |
| ------ | ---------------------------- | ---- | ----- |
| 1      | Critical fixes + Performance | 1, 2 | 7     |
| 2      | Cleanup + Docs               | 3, 4 | 4.6   |

---

## 6. Infrastructure Recommendations

N/A for seat domain — no worker tuning or Redis topology changes needed. All fixes are application-layer.

---

## 7. Test Plan

| Test File                                         | Coverage Target                                                                       |
| ------------------------------------------------- | ------------------------------------------------------------------------------------- |
| `tests/unit/domains/seat/seat.repository.test.ts` | All new Lua scripts (lock/unlock atomic, invite-accept, delete-invite, reverse index) |
| New: handler integration tests                    | Auth policy, seatCount enforcement, invite-when-seated rejection                      |

---

## 8. Rollback Procedures

All PRs are independently revertible via `git revert <merge-commit>`. No data migrations involved — all changes are application logic. Redis key patterns remain backward-compatible (reverse index keys are additive).

**Critical**: If SEAT-005 (reverse index) is reverted, ensure `getUserSeat()` falls back to HGETALL scan (the old implementation). No data cleanup needed — orphaned reverse index keys will expire naturally if given TTL, or can be ignored.
